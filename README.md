# PySpark with Databricks

**Azure Databricks** is an Apache Spark-based big data analytics and machine learning framework optimized for the Microsoft Azure Cloud.
Databricks is integrated with Azure to provide one-click setup, streamlined workflows, and an interactive workspace that enables collaboration between data scientists, data engineers, and business analysts.

This repository consists materials for a 3-day Python+Spark+PySpark course.


## Day 1
- Intro to Python. 
- Spark Overview.

## Day 2
- Databricks Overview.
- Querying data in Databricks.
- PySpark.
- Data Manipulation Exercises.

## Day 3
- Spark Performance Tuning.
- Machine Learning with MLlib.

# References
- [Excellent writeup of PySpark with cheatsheets](https://runawayhorse001.github.io/LearningApacheSpark/preface.html)
- [End-to-end ML pipeline (for the advanced and impatient)](https://github.com/colbyford/PyDataCLT_Jan2020)
- [Microsoft Learning Labs, Databricks Intro](https://github.com/MicrosoftLearning/databricks-intro)
- [Microsoft Learning Labs, Databricks ML](https://github.com/MicrosoftLearning/databricks-ml)
- [Physical Plans in Spark (talk)](https://www.youtube.com/watch?v=99fYi2mopbs)
- [Query plans in Spark](https://towardsdatascience.com/mastering-query-plans-in-spark-3-0-f4c334663aa4)
- [SparkSQL vs PySpark (probably outdated)](https://community.cloudera.com/t5/Community-Articles/Spark-RDDs-vs-DataFrames-vs-SparkSQL/ta-p/246547)